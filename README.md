# "Привет, Whoosh!" - раунд 2

## Задача
Написать код, который будет:
- генерировать сырой текстовый файл, состоящий из телефонных номеров
- создавать итоговый файл, который будет состоять из номеров исходного файла, но в отсортированном порядке 
- измерять время своего выполнения

## Решение (и как на него можно повлиять!)
### Генерация
В файле `config.py` есть переменная `NUMBER_OF_ROWS_IN_GENERATED_FILE`.
Она регулирует то, сколько всего номеров будет сгенерировано в сыром файле.
Генерация не ограничена уже записанными номерами - то есть значение этой настройки может 
превышать число всех возможных комбинаций цифр в номерах (при сортировке одинаковые номера будут идти подряд).

Также, в `config.py` есть переменная `LIMIT_ROWS_TO_WRITE_PER_TIME`.
Она регулирует то, сколько сгенерированных номеров будет записано в сырой файл-источник за раз.
Необходимость этой переменной обусловлена тем, что юзер может захотеть сгенерировать миллиарды_миллионов_тысяч_сотен номеров.
То есть вместо того, чтобы в один момент времени держать огромный список в оперативной памяти,
код будет генерировать и записывать номера пачками размером `LIMIT_ROWS_TO_WRITE_PER_TIME`


### Считывание сгенерированного файла
В `config.py` есть переменная `READER_LINES_PER_FETCH`. 
Она регулирует то, сколько строк за раз будет читать ридер файла - эта сущность и переменная в конфиге необходимы для того,
чтобы получившийся файл считывался не полностью, а с "пагинацией" - инстанс ридера запоминает последнюю считанную строку,
и потом считывает следующие `READER_LINES_PER_FETCH`.

### Разделение большого файла-источника на несколько маленьких
В `config.py` есть переменная `SPLITTER_MAX_ROW_IN_FILE`. 
Она регулирует то, сколько строк могут вмещать в себя файл(-ы), на которые будет дробиться большой сырой файл.
То есть, если файл-источник состоит из 10_000 строк (`NUMBER_OF_ROWS_IN_GENERATED_FILE=10_000`) и
`SPLITTER_MAX_ROW_IN_FILE=1_000`, то код создаст 10 "временных" файлов.

Также в инстанс сплиттера можно передать кастомный хэндлер для препроцессинга строк, записываемых в маленькие файлы. 
Сейчас этот хэндлер просто сортирует их - это необходимо для дальнейшей сортировки слиянием. Но туда можно передать 
больше логики, которая, например, будет не сохранять первые символы.

### Сортировка слиянием
Для каждого маленького файла создается сущность ридера (ридеры менеджментят то, насколько прочитан их файл -
это необходимо, так как файлы будут считываться с разной скоростью). Все ридеры образуют пул текущих минимальных значений.
Изначальный размер пула равен числу промежуточных файлов. По ходу выполнения сортировки слиянием пул будет сужаться, 
так как будет выбираться минимальный элемент из пула минимальных.

## Code style
Для всех действий реализовано:
- Отдельные классы для "простого"/"низкоуровневого" менеджмента файлов (создание, чтение "со сдвигом"), генерации случайных номеров
- Отдельные "бизнесовые" классы, в которых реализована основная логика решения. Они обращаются к простым классам для решения частных задач.

В коде учел простую структуру - отдельно инициализирутся зависимости (см. `deps`), есть явный энтрипоинт, 
отдельно хранится код каждого слоя, и есть конфиг (для разных ПК и тест-кейсов могут быть разные параметры)

## А где энтрипоинт?
`src/__main__.py`

## Куда смотреть после выполнения?
В `resources` есть txt-файл c "тестовыми" данными - там же появятся "промежуточные" файлы и итоговый `result.txt`

## Roadmap и TODOs!
- Препроцессинг сырых данных
- Рефакторинг чтения "со сдвигом" - нужно удалить повторное открытие
- Переписать классы на pythonic ООП синтаксис (дескрипторы, проперти)
- Удаление промежуточных файлов
- CLI для применения скрипта к любому текстовому файлу и сохранению файла в указнное юзером место (+`argparse`)
- Валидация input файла
- Кастомные исключения в `services`